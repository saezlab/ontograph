{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pronto\n",
    "\n",
    "from pronto import LiteralPropertyValue, Xref\n",
    "from pronto import Synonym, SynonymData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids = pd.read_table(\n",
    "    filepath_or_buffer=\"../data/in/lipids.tsv.gz\",\n",
    "    encoding=\"latin-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.columns = df_lipids.columns.map(lambda x: ''.join(c if c.isalnum() or c == '_' else '_' for c in str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids[df_lipids[\"Lipid_ID\"] == 'SLM:000000339']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids[\"Level\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Generate Ontology object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_ONTOLOGY = {\n",
    "    \"ontology\": \"swisslipids\",  # This sets the ontology name\n",
    "    \"title\": \"SwissLipids Ontology\",\n",
    "    \"description\": \"Ontology representing SwissLipids data, including lipid IDs, classes, and parent relationships.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"creators\": [\"SIB Swiss Institute of Bioinformatics.\"],\n",
    "    \"license\": \"CC-BY 4.0\",\n",
    "    \"created\": \"2025-08-29\",\n",
    "}\n",
    "\n",
    "\n",
    "ID_COLUMNS = {\n",
    "    \"term_id\": \"Lipid_ID\",\n",
    "    \"parent_id\": \"Parent\",\n",
    "    \"class_id\": \"Lipid_class_\"\n",
    "}\n",
    "\n",
    "def write_to_obo(file_path, ontology):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        ontology.dump(f, format=\"obo\")\n",
    "\n",
    "\n",
    "def add_ontology_metadata(ontology, metadata):\n",
    "    for key, value in metadata.items():\n",
    "        setattr(ontology.metadata, key, value)\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    # Strip values in columns (vectorized)\n",
    "    obj_cols = dataset.select_dtypes(include=\"object\").columns\n",
    "    dataset[obj_cols] = dataset[obj_cols].apply(lambda col: col.str.strip())\n",
    "    return dataset\n",
    "\n",
    "METADATA_ONTOLOGY = {\n",
    "    \"ontology\": \"swisslipids\",  # This sets the ontology name\n",
    "    \"title\": \"SwissLipids Ontology\",\n",
    "    \"description\": \"Ontology representing SwissLipids data, including lipid IDs, classes, and parent relationships.\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"creators\": [\"SIB Swiss Institute of Bioinformatics.\"],\n",
    "    \"license\": \"CC-BY 4.0\",\n",
    "    \"created\": \"2025-08-29\",\n",
    "}\n",
    "\n",
    "\n",
    "ID_COLUMNS = {\n",
    "    \"term_id\": \"Lipid_ID\",\n",
    "    \"parent_id\": \"Parent\",\n",
    "    \"class_id\": \"Lipid_class_\"\n",
    "}\n",
    "\n",
    "def write_to_obo(file_path, ontology):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        ontology.dump(f, format=\"obo\")\n",
    "\n",
    "\n",
    "def add_ontology_metadata(ontology, metadata):\n",
    "    for key, value in metadata.items():\n",
    "        setattr(ontology.metadata, key, value)\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    # Strip values in columns (vectorized)\n",
    "    obj_cols = dataset.select_dtypes(include=\"object\").columns\n",
    "    dataset[obj_cols] = dataset[obj_cols].apply(lambda col: col.str.strip())\n",
    "    return dataset\n",
    "\n",
    "def generate_ontology_from_table(dataset: pd.DataFrame, id_columns: dict, metadata:dict):\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    dataset = preprocess_dataset(dataset)\n",
    "\n",
    "    # Create Ontology\n",
    "    ontology = pronto.Ontology()\n",
    "    \n",
    "    # Add ontology metadata\n",
    "    add_ontology_metadata(ontology=ontology, metadata=metadata)\n",
    "\n",
    "    # --- 1. Collect all unique IDs from all relevant columns ---\n",
    "    term_col = dataset[id_columns[\"term_id\"]].dropna().astype(str)\n",
    "    class_col = dataset[id_columns[\"class_id\"]].dropna().astype(str)\n",
    "    parent_col = dataset[id_columns[\"parent_id\"]].dropna().astype(str)\n",
    "\n",
    "    all_terms_id = set(term_col.unique())\n",
    "    all_classes_id = {term.strip() for classes in class_col.str.split(\"|\") for term in classes if term.strip()}\n",
    "    all_parents_id = {term.strip() for term in parent_col if term.strip()}\n",
    "    \n",
    "    all_unique_ids = all_terms_id | all_classes_id | all_parents_id\n",
    "    \n",
    "    print(f\"Total unique terms to create: {len(all_unique_ids)}\")\n",
    "\n",
    "    # --- 2. Create all terms ONCE without any properties ---\n",
    "    for term_id in all_unique_ids:\n",
    "        ontology.create_term(term_id)\n",
    "\n",
    "    # --- REFACTOR: Define annotation columns in a list for maintainability ---\n",
    "    annotation_columns = [\n",
    "        (\"Level\", \"Level\", \"xsd:string\"),\n",
    "        (\"Components\", \"Components_\"),\n",
    "        (\"SMILES__pH7_3\", \"SMILES__pH7_3_\"),\n",
    "        (\"InChI__pH7_3\", \"InChI__pH7_3_\"),\n",
    "        (\"InChI_key__pH7_3\", \"InChI_key__pH7_3_\"),\n",
    "        (\"Formula__pH7_3\", \"Formula__pH7_3_\"),\n",
    "        (\"Charge__pH7_3\", \"Charge__pH7_3_\", \"xsd:integer\"),\n",
    "        (\"Mass__pH7_3\", \"Mass__pH7_3_\", \"xsd:float\"),\n",
    "        (\"Exact_Mass__neutral_form\", \"Exact_Mass__neutral_form_\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M\", \"Exact_m_z_of__M___\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_H__\", \"Exact_m_z_of__M_H__\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_K___\", \"Exact_m_z_of__M_K___\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_Na__\", \"Exact_m_z_of__M_Na__\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_Li__\", \"Exact_m_z_of__M_Li__\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_NH4__\", \"Exact_m_z_of__M_NH4__\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_Cl__\", \"Exact_m_z_of__M_Cl__\", \"xsd:float\"),\n",
    "        (\"Exact_m_z_of__M_OAc___\", \"Exact_m_z_of__M_OAc___\", \"xsd:float\"),\n",
    "        (\"Abbreviation\", \"Abbreviation_\")\n",
    "    ]\n",
    "\n",
    "    xref_columns = [\"CHEBI\", \"LIPID_MAPS\", \"HMDB\", \"MetaNetX\"]\n",
    "\n",
    "\n",
    "    # --- 3. Iterate through the data to add properties and relationships ---\n",
    "    for row in dataset.itertuples(index=False):\n",
    "        term_id = getattr(row, id_columns.get(\"term_id\"))\n",
    "        \n",
    "        if pd.isna(term_id):\n",
    "            continue\n",
    "\n",
    "        term = ontology.get_term(term_id)\n",
    "\n",
    "        if pd.notna(getattr(row, \"Name\")):\n",
    "            term.name = getattr(row, \"Name\")\n",
    "        \n",
    "        synonyms = getattr(row, \"Synonyms_\")\n",
    "        if pd.notna(synonyms):\n",
    "            for syn_text in str(synonyms).split(\"|\"):\n",
    "                syn_text = syn_text.strip()\n",
    "                if syn_text:\n",
    "                    term.add_synonym(syn_text, scope=\"RELATED\")\n",
    "\n",
    "        # --- REFACTOR: Loop through annotation columns and add them with correct data types ---\n",
    "        for item in annotation_columns:\n",
    "            prop_name, col_name = item[0], item[1]\n",
    "            xsd_type = item[2] if len(item) > 2 else None\n",
    "            \n",
    "            value = getattr(row, col_name)\n",
    "            if pd.notna(value):\n",
    "                if xsd_type:\n",
    "                    term.annotations.add(LiteralPropertyValue(prop_name, str(value), datatype=xsd_type))\n",
    "                else:\n",
    "                    term.annotations.add(LiteralPropertyValue(prop_name, str(value)))\n",
    "\n",
    "        new_xrefs = set(term.xrefs)\n",
    "        for col_name in xref_columns:\n",
    "            value = getattr(row, col_name)\n",
    "            if pd.notna(value):\n",
    "                # Xrefs can also be pipe-separated\n",
    "                for xref_id in str(value).split('|'):\n",
    "                    xref_id = xref_id.strip()\n",
    "                    if xref_id:\n",
    "                        new_xrefs.add(Xref(xref_id))\n",
    "        if new_xrefs:\n",
    "            term.xrefs = frozenset(new_xrefs)\n",
    "\n",
    "        # Add parent relationship\n",
    "        parent_id = getattr(row, id_columns.get(\"parent_id\"))\n",
    "        if pd.notna(parent_id):\n",
    "            parent_term = ontology.get_term(parent_id.strip())\n",
    "            parent_term.subclasses().add(term)\n",
    "\n",
    "        # Add class relationship\n",
    "        classes_id = getattr(row, id_columns.get(\"class_id\"))\n",
    "        if pd.notna(classes_id):\n",
    "            for item in str(classes_id).split(\"|\"):\n",
    "                class_term_id = item.strip()\n",
    "                if class_term_id:\n",
    "                    class_term = ontology.get_term(class_term_id)\n",
    "                    class_term.subclasses().add(term)\n",
    "\n",
    "    return ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Lipid_ID',\n",
    "#'Level',\n",
    "#'Name',\n",
    "#'Abbreviation_',\n",
    "#'Synonyms_',\n",
    "#'Lipid_class_', \n",
    "#'Parent',\n",
    "'Components_',\n",
    "'SMILES__pH7_3_',\n",
    "'InChI__pH7_3_',\n",
    "'InChI_key__pH7_3_',\n",
    "'Formula__pH7_3_',\n",
    "'Charge__pH7_3_',\n",
    "'Mass__pH7_3_',\n",
    "'Exact_Mass__neutral_form_',\n",
    "'Exact_m_z_of__M___',\n",
    "'Exact_m_z_of__M_H__',\n",
    "'Exact_m_z_of__M_K___',\n",
    "'Exact_m_z_of__M_Na__',\n",
    "'Exact_m_z_of__M_Li__',\n",
    "'Exact_m_z_of__M_NH4__',\n",
    "'Exact_m_z_of__M_H__',\n",
    "'Exact_m_z_of__M_Cl__',\n",
    "'Exact_m_z_of__M_OAc___',\n",
    "'CHEBI',\n",
    "'LIPID_MAPS',\n",
    "'HMDB',\n",
    "'MetaNetX',\n",
    "'PMID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "swissontology = generate_ontology_from_table(dataset=df_lipids,\n",
    "                                             id_columns=ID_COLUMNS,\n",
    "                                             metadata=METADATA_ONTOLOGY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(swissontology.terms())) # 779249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_obo(file_path=\"../data/out/lipids.obo\", ontology=swissontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Generate Mapping File Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_chebi(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    val_str = str(val).strip()\n",
    "    if re.match(r\"^CHEBI:\\d+$\", val_str):\n",
    "        return val_str\n",
    "    digits = re.findall(r\"\\d+\", val_str)\n",
    "    return f\"CHEBI:{digits[0]}\" if digits else val_str\n",
    "\n",
    "def fix_lipid_maps(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    val_str = str(val).strip()\n",
    "    if re.match(r\"^LM[A-Z0-9]+$\", val_str):\n",
    "        return val_str\n",
    "    lm_match = re.search(r\"(LM[A-Z0-9]+)\", val_str)\n",
    "    return lm_match.group(1) if lm_match else val_str\n",
    "\n",
    "def fix_hmdb(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    val_str = str(val).strip()\n",
    "    if re.match(r\"^HMDB\\d+$\", val_str):\n",
    "        return val_str\n",
    "    digits = re.findall(r\"\\d+\", val_str)\n",
    "    return f\"HMDB{digits[0]}\" if digits else val_str\n",
    "\n",
    "def fix_metanetx(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    val_str = str(val).strip()\n",
    "    if re.match(r\"^MNXM\\d+$\", val_str):\n",
    "        return val_str\n",
    "    digits = re.findall(r\"\\d+\", val_str)\n",
    "    return f\"MNXM{digits[0]}\" if digits else val_str\n",
    "\n",
    "def fix_crossref_columns(df):\n",
    "    df = df.copy()  # Ensure we work on a copy\n",
    "    if \"CHEBI\" in df.columns:\n",
    "        df.loc[:, \"CHEBI\"] = df[\"CHEBI\"].apply(fix_chebi)\n",
    "    if \"LIPID_MAPS\" in df.columns:\n",
    "        df.loc[:, \"LIPID_MAPS\"] = df[\"LIPID_MAPS\"].apply(fix_lipid_maps)\n",
    "    if \"HMDB\" in df.columns:\n",
    "        df.loc[:, \"HMDB\"] = df[\"HMDB\"].apply(fix_hmdb)\n",
    "    if \"MetaNetX\" in df.columns:\n",
    "        df.loc[:, \"MetaNetX\"] = df[\"MetaNetX\"].apply(fix_metanetx)\n",
    "    return df\n",
    "\n",
    "def generate_mapping_file_from_table(dataset, columns: list, new_name_columns:list):\n",
    "    dataframe = dataset[columns]\n",
    "    dataframe = fix_crossref_columns(dataframe)\n",
    "    dataframe.columns = new_name_columns\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns=[\"Lipid_ID\", \"CHEBI\", \"LIPID_MAPS\", \"HMDB\", \"MetaNetX\"]\n",
    "new_name_columns = [\n",
    "    \"swiss_lipid_id\",\n",
    "    \"chebi_id\",\n",
    "    \"lipid_maps_id\",\n",
    "    \"hmdb_id\",\n",
    "    \"metanetx_id\"\n",
    "]\n",
    "\n",
    "mapping_file = generate_mapping_file_from_table(df_lipids, list_columns, new_name_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids[df_lipids[\"Lipid_class_\"] == \"SLM:000001080\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file[mapping_file[\"chebi_id\"] == \"CHEBI:33234\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ids(mapping_df, source_format: str, target_format: str, source_ids: list) -> list:\n",
    "    \"\"\"\n",
    "    Translate a list of identifiers from source_format to target_format using mapping_df.\n",
    "    Prints IDs that fail and shows a summary at the end.\n",
    "\n",
    "    Args:\n",
    "        mapping_df (pd.DataFrame): The mapping table.\n",
    "        source_format (str): The column name for the source format.\n",
    "        target_format (str): The column name for the target format.\n",
    "        source_ids (list): List of identifiers to translate.\n",
    "\n",
    "    Returns:\n",
    "        list: List of translated identifiers (None for failed).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    failed = []\n",
    "    for source_id in source_ids:\n",
    "        try:\n",
    "            row = mapping_df[mapping_df[source_format] == source_id]\n",
    "            if row.empty:\n",
    "                print(f\"ID not found: {source_id}\")\n",
    "                results.append(None)\n",
    "                failed.append(source_id)\n",
    "            else:\n",
    "                target_id = row.iloc[0][target_format]\n",
    "                if pd.isna(target_id) or not isinstance(target_id, str) or not target_id.strip():\n",
    "                    print(f\"Target format missing for: {source_id}\")\n",
    "                    results.append(None)\n",
    "                    failed.append(source_id)\n",
    "                else:\n",
    "                    results.append(target_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {source_id}: {e}\")\n",
    "            results.append(None)\n",
    "            failed.append(source_id)\n",
    "    print(f\"\\nSummary: {len(source_ids) - len(failed)} IDs converted, {len(failed)} failed.\")\n",
    "    if failed:\n",
    "        print(\"Failed IDs:\", failed)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_lipid_ids = [\n",
    "    \"SLM:000000042\",\n",
    "    \"SLM:000001080\",\n",
    "    \"SLM:000000421\",\n",
    "    \"SLM:000000651\",\n",
    "]\n",
    "\n",
    "chebi_ids = translate_ids(mapping_df=mapping_file,\n",
    "                          source_format=\"swiss_lipid_id\",\n",
    "                          #target_format=\"chebi_id\",\n",
    "                          target_format=\"hmdb_id\",\n",
    "                          source_ids=swiss_lipid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = pronto.Ontology(\"../data/out/lipids.obo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in onto.relationships():\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "term = onto.get_term(\"SLM:000755122\")  # replace with your term ID\n",
    "term.annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ontograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
